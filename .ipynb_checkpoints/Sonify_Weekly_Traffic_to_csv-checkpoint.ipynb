{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72c00a3d-308b-4c67-9561-11032a7e1d02",
   "metadata": {},
   "source": [
    "# 1. Introduction: Can You Hear the Internet?\n",
    "Have you ever wondered what your internet usage sounds like? We're used to seeing data in charts and graphs, but what if we could represent it with music? This was the question that sparked the Network Communications Project.\n",
    "\n",
    "In this article, I'll walk you through how I took a raw dataset of my university's weekly network traffic and transformed it into a musical piece. The goal was to \"sonify\" the download and upload statistics, creating a unique auditory representation of data.\n",
    "\n",
    "We'll use Python's Pandas library for the data manipulation and a fascinating online tool called [TwoTone MIDI Out Beta](https://twotone-midiout-beta.netlify.app/)  to generate the final musical output. Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189df8ed-2920-4b71-8c68-ce7963b968e5",
   "metadata": {},
   "source": [
    "# 2. The Raw Material: Sourcing the Network Data\n",
    "\n",
    "Every data story starts with the data. For this project, the source was the Janet Netsight Portal, which tracks network traffic for UK educational institutions.\n",
    "\n",
    "**The Goal:** To get a historical view of the \"In\" (download) and \"Out\" (upload) traffic for my University.  \n",
    "**The Challenge:** The portal doesn't allow for a simple \"download all\" button. Through experimentation, I found that requesting a date range of approximately 549 days (e.g., from July 2023 to January 2025) provided the daily data I needed.  \n",
    "**A Quick Note on Perspective:** The data is labeled from the provider's (Janet's) perspective. This means \"In\" is data coming into their network from the university (our upload), and \"Out\" is data going out to the university (our download). We'll need to remember to swap these later!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df5ad61-27b9-4cb4-8bfe-205140044b9c",
   "metadata": {},
   "source": [
    "# 3. The Setup: Loading and Cleaning the Data  \n",
    "\n",
    "With several CSV files downloaded, the first step is to load them into a single, clean DataFrame using Pandas. We'll use Python's glob library to find all the CSV files in our input directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5019f1-db0d-4f14-a0e3-71c46b938ce0",
   "metadata": {},
   "source": [
    "## Code Block 1: Imports and File Loading  \n",
    "First, let's import our libraries and set up the path to our data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88fe1064-531e-4188-8d13-bcd51c0b21b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Define the path to the input folder and get a list of all CSV files\n",
    "path = rf'./input/*.csv'\n",
    "files = glob.glob(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fd33eb-e2bc-4b4a-85a2-98b4ed867be0",
   "metadata": {},
   "source": [
    "Now, we'll loop through each file, read it into a Pandas DataFrame, and combine them. A small trick here is to use a header_flag to ensure we only include the header row from the very first file, creating a clean, unified dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94c9bac1-f210-4382-ba80-c9cf15ddc11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to hold each DataFrame\n",
    "df_list = []\n",
    "header_flag = False\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # Only keep the header from the first file\n",
    "    if not header_flag:\n",
    "        header_flag = True\n",
    "    else:\n",
    "        # For subsequent files, skip the header row\n",
    "        df = df.iloc[1:]\n",
    "\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatenate all DataFrames and sort by time\n",
    "final_df = pd.concat(df_list, ignore_index=True)\n",
    "df = final_df.sort_values('Time', ascending=True).copy()\n",
    "\n",
    "# As mentioned, Janet's 'out' is our download ('in') and vice-versa.\n",
    "# Let's rename the columns to reflect our perspective.\n",
    "df.columns = ['Time', 'in', 'out']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4ab79d-c733-4c54-a412-7e95be56ca00",
   "metadata": {},
   "source": [
    "# 4: Feature Engineering - Building a Richer Musical Palette\n",
    "\n",
    "Raw data is just the beginning. To transform our data into a piece with rhythm, texture, and distinct movements, we need to create more features. Think of these new data columns as potential instruments or triggers in our final musical score.\n",
    "\n",
    "The goal is to create flags that mark specific points in time, such as the start of a week, a month, or a quarter. We can also add context, like whether a given day is a workday or a weekend.\n",
    "\n",
    "Here are the features we'll add to our daily data:\n",
    "\n",
    "* Week_Start: A flag for Monday to mark the start of a new week.\n",
    "* Month_Start: A flag for the first day of the month.\n",
    "* Year_Start: A flag for the first day of the year.\n",
    "* Week_Number: The week number of the year (1-52/53).\n",
    "\n",
    "Let's generate these using the  datetime functionality built into Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa67889-f545-45e4-9baf-a03bf586d917",
   "metadata": {},
   "source": [
    "## Code Block 2: Creating Time-Based Features\n",
    "\n",
    "First, we ensure the 'Time' column is in the correct datetime format. Then, we use the .dt accessor to pull out all the information we need. We use np.where to create our flags: if a condition is true (e.g., the day is a Monday), we assign it a value of 256; otherwise, it's 0. This high value creates a clear signal for our sonification tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "563b1b3a-ace5-4a9a-bb08-5dff2f98adc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Time' column to a proper datetime format\n",
    "df['Time'] = pd.to_datetime(df['Time'], format='mixed')\n",
    "\n",
    "# Extract time-based features that we can use for musical cues\n",
    "df['Week_Start'] = np.where(df['Time'].dt.day_name() == 'Monday', 256, 0)\n",
    "df['Month_Start'] = np.where(df['Time'].dt.is_month_start, 256, 0)\n",
    "df['Year_Start'] = np.where(df['Time'].dt.is_year_start, 256, 0)\n",
    "\n",
    "# We'll also extract the week number and year for grouping\n",
    "df['Week_Number'] = df['Time'].dt.isocalendar().week\n",
    "df['Year'] = df['Time'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce08c58-24f5-4ab0-941b-312e7b6a53de",
   "metadata": {},
   "source": [
    "# 5. From Daily Noise to a Weekly Melody\n",
    "Daily data can be noisy. To create a smoother, more melodic output, I decided to aggregate the data by week, taking the average (mean) traffic for each week."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17c8cb6-38b6-4936-8194-d02c9a3e7a23",
   "metadata": {},
   "source": [
    "## Code Block 3: Grouping by Week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbbddf6e-040c-43a1-b23a-887e5a5000ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by Year and Week Number, then calculate the weekly mean for 'in' and 'out' traffic\n",
    "weekly_df = df.groupby(['Year', 'Week_Number']).agg(\n",
    "    in_mean=('in', 'mean'),\n",
    "    out_mean=('out', 'mean'),\n",
    "    Year_Start=('Year_Start', 'max'), # Carry over our markers\n",
    "    Month_Start=('Month_Start', 'max')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb8f496-1676-4488-9698-2fb154e6ce37",
   "metadata": {},
   "source": [
    "# 6. The Core Challenge: Proportional Sonification  \n",
    "\n",
    "Here we face the most interesting challenge. Download (in) traffic is often much larger than upload (out) traffic. If we map each to a musical scale independently, the highest upload value and the highest download value would both play the same top note. This would completely hide the fact that downloads are significantly higher.\n",
    "\n",
    "To solve this, we need to maintain the proportional relationship between the two.\n",
    "\n",
    "**The Solution:**\n",
    "\n",
    "1. Find the maximum value for both in and out traffic across the entire dataset.\n",
    "2. Calculate a scaling_factor (out_max / in_max).\n",
    "3. Quantize both data streams into a set number of bins (e.g., 48, which maps nicely to musical notes).\n",
    "4. Multiply the quantized upload data by the scaling_factor. This scales it down, ensuring its musical representation is proportionally lower than the download data, just like the real traffic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d6f455-b412-4fb8-9b08-1687153968ef",
   "metadata": {},
   "source": [
    "## Code Block 4: Quantizing and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b508fa5-b9aa-44a0-adc8-dd8c0414ab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calculate the scaling factor\n",
    "in_max = df['in'].max()\n",
    "out_max = df['out'].max()\n",
    "scaling_factor = out_max / in_max\n",
    "\n",
    "# 3. Quantize the weekly average 'in' data into 48 bins\n",
    "weekly_df['in_quant'] = pd.cut(weekly_df['in_mean'], bins=48, labels=range(1, 49)).astype(int)\n",
    "\n",
    "# 4. Quantize the 'out' data and then apply the scaling factor\n",
    "out_quant_scaled = (pd.cut(weekly_df['out_mean'], bins=48, labels=range(1, 49)).astype(float) * scaling_factor)\n",
    "weekly_df['out_quant'] = out_quant_scaled.round().astype(int).clip(lower=1) # a value of 0 would be silence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50d1160-43c2-444d-a0c3-6c5d39f776d5",
   "metadata": {},
   "source": [
    "# 7. Adding Dynamics: Representing Up and Down Trends\n",
    "To make the music more dynamic, I wanted to represent not just the volume of traffic, but also its direction. Is the traffic increasing or decreasing week-on-week?\n",
    "\n",
    "We can create two new data streams for each of our in and out values:\n",
    "\n",
    "* An _up column that only contains a value if the traffic increased from the previous week.\n",
    "* A _down column that only contains a value if the traffic decreased.\n",
    "In the TwoTone tool, we can then assign different arpeggio styles (e.g., ascending for \"up\", descending for \"down\") to these streams, creating a richer sonic texture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640f1b65-fd8f-41d1-83d7-a27f0986a4b7",
   "metadata": {},
   "source": [
    "## Code Block 5: Capturing Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5babb4e-8916-4d5b-948c-0117715e7770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Week_Number</th>\n",
       "      <th>in_mean</th>\n",
       "      <th>out_mean</th>\n",
       "      <th>Year_Start</th>\n",
       "      <th>Month_Start</th>\n",
       "      <th>in_quant</th>\n",
       "      <th>out_quant</th>\n",
       "      <th>in_up</th>\n",
       "      <th>out_up</th>\n",
       "      <th>in_down</th>\n",
       "      <th>out_down</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>5.504009e+07</td>\n",
       "      <td>5.440811e+08</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>1.283560e+08</td>\n",
       "      <td>1.548700e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>1.349566e+08</td>\n",
       "      <td>1.562483e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>1.548510e+08</td>\n",
       "      <td>1.763358e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>57</td>\n",
       "      <td>6</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>1.707573e+08</td>\n",
       "      <td>1.828013e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Week_Number       in_mean      out_mean  Year_Start  Month_Start  \\\n",
       "0  2019            1  5.504009e+07  5.440811e+08         256          256   \n",
       "1  2019            2  1.283560e+08  1.548700e+09           0            0   \n",
       "2  2019            3  1.349566e+08  1.562483e+09           0            0   \n",
       "3  2019            4  1.548510e+08  1.763358e+09           0            0   \n",
       "4  2019            5  1.707573e+08  1.828013e+09           0          256   \n",
       "\n",
       "   in_quant  out_quant  in_up  out_up  in_down  out_down  \n",
       "0         2         14      0       0        0         0  \n",
       "1         5         49      5      49        0         0  \n",
       "2         5         52      0      52        0         0  \n",
       "3         6         57      6      57        0         0  \n",
       "4         7         60      7      60        0         0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create columns to capture increasing trends\n",
    "weekly_df['in_up'] = weekly_df['in_quant'].where(weekly_df['in_quant'] > weekly_df['in_quant'].shift(), 0)\n",
    "weekly_df['out_up'] = weekly_df['out_quant'].where(weekly_df['out_quant'] > weekly_df['out_quant'].shift(), 0)\n",
    "\n",
    "# Create columns to capture decreasing trends\n",
    "weekly_df['in_down'] = weekly_df['in_quant'].where(weekly_df['in_quant'] < weekly_df['in_quant'].shift(), 0)\n",
    "weekly_df['out_down'] = weekly_df['out_quant'].where(weekly_df['out_quant'] < weekly_df['out_quant'].shift(), 0)\n",
    "\n",
    "# Display the first few rows of our final DataFrame\n",
    "# On Medium, you can paste a screenshot of the output or just show the .head()\n",
    "weekly_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0c6c815-ecbf-448f-be2c-d73f82577bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_df.to_csv(\"./output/Processed_traffic.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9ffed2-7aa6-4fc5-9cee-c4a5f394ea49",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 8. The Final Composition: Making Music with TwoTone  \n",
    "\n",
    "With our data prepared, the final step is to bring it to life. I used the [TwoTone MIDI Out Beta](https://twotone-midiout-beta.netlify.app/) . You simply upload the final CSV, map your data columns to musical parameters, and press play.  \n",
    "Here are the settings I found worked best to create a clear and pleasant composition from the weekly data:\n",
    "\n",
    "**Download Data (in_quant)**\n",
    "\n",
    "* Instrument: Double Bass\n",
    "* Range: 2 Octaves\n",
    "* Speed: 4x\n",
    "* Style: Arpeggio (4 notes, ascending)\n",
    "\n",
    "**Upload Data (out_quant)**\n",
    "\n",
    "* Instrument: Glockenspiel\n",
    "* Range: 2 Octaves\n",
    "* Speed: 2x\n",
    "* Style: Ascending\n",
    "\n",
    "The low, heavy notes of the double bass represent the high volume of download traffic, while the lighter, twinkling glockenspiel represents the lower volume of upload traffic. The time markers for month and year starts were used as cues to add speech annotations (e.g., \"2024,\" \"February\") using an external audio editor for the final video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7011db1-420a-47e4-b011-d67fe3025d14",
   "metadata": {},
   "source": [
    "# 9. Conclusion\n",
    "This project was a fascinating journey into a new, for me, form of data representation. It demonstrates that with a bit of creativity and some data manipulation skills, we can find stories in data that go beyond traditional charts. Sonification offers a uniquely emotional and intuitive way to experience data patterns over time.\n",
    "\n",
    "The final CSV file is ready for sonification. I encourage you to download the notebook from my GitHub [link to your GitHub repo here], experiment with the data, and create your own data-driven music with the [TwoTone MIDI Out Beta](https://twotone-midiout-beta.netlify.app/)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45728590-e175-4488-810d-8281a1d74c92",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04cbfd46-84f7-4068-a405-3f399dc3d7d7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f734874b-7e72-4350-af6d-e8ff7865fa48",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57f697d7-87ee-4f9d-86f5-fddef241bb45",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5979183-4a0d-4e8c-a10d-d1511f94bc44",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
